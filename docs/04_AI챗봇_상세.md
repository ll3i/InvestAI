# ğŸ¤– Pixie AI ì±—ë´‡ í˜ì´ì§€ ê°œë°œ ë¬¸ì„œ

## ğŸ¯ í˜ì´ì§€ ê°œìš”

### ëª©ì 
íˆ¬ììì—ê²Œ ê°œì¸í™”ëœ íˆ¬ì ìƒë‹´ê³¼ ì‹¤ì‹œê°„ ì§ˆì˜ì‘ë‹µì„ ì œê³µí•˜ëŠ” AI ê¸°ë°˜ ì±—ë´‡ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥
- ë‹¤ì¤‘ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ (AI-A â†’ AI-A2 â†’ AI-B â†’ Final)
- ì‹¤ì‹œê°„ íˆ¬ì ìƒë‹´
- ê°œì¸í™”ëœ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„
- ì‹œì¥ ë™í–¥ ë¶„ì„
- ìì—°ì–´ ëŒ€í™” ì¸í„°í˜ì´ìŠ¤

## ğŸ—ï¸ ê¸°ìˆ ì  ì•„í‚¤í…ì²˜

### í”„ë¡ íŠ¸ì—”ë“œ êµ¬ì¡°
```
web/templates/
â”œâ”€â”€ chatbot.html              # ë©”ì¸ ì±—ë´‡ í˜ì´ì§€
â”œâ”€â”€ chatbot_widget.html       # ì±—ë´‡ ìœ„ì ¯
â””â”€â”€ chatbot_history.html      # ëŒ€í™” ê¸°ë¡ í˜ì´ì§€
```

### ë°±ì—”ë“œ êµ¬ì¡°
```
web/
â”œâ”€â”€ app.py                     # ì±—ë´‡ ê´€ë ¨ ë¼ìš°íŠ¸
â”œâ”€â”€ blueprints/
â”‚   â””â”€â”€ chat/                 # ì±—ë´‡ ê´€ë ¨ ë¼ìš°íŠ¸
â””â”€â”€ services/
    â”œâ”€â”€ ai_chat_service.py    # AI ì±—ë´‡ ì„œë¹„ìŠ¤
    â”œâ”€â”€ conversation_service.py # ëŒ€í™” ê´€ë¦¬
    â””â”€â”€ memory_service.py     # ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬
```

## ğŸ“± UI/UX ì„¤ê³„

### ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤
1. **ëŒ€í™”ì°½ ë ˆì´ì•„ì›ƒ**
   - ì‚¬ìš©ì ë©”ì‹œì§€ (ì˜¤ë¥¸ìª½)
   - AI ì‘ë‹µ (ì™¼ìª½)
   - ì‹œìŠ¤í…œ ë©”ì‹œì§€ (ì¤‘ì•™)

2. **ì…ë ¥ ì˜ì—­**
   - í…ìŠ¤íŠ¸ ì…ë ¥ì°½
   - ìŒì„± ì…ë ¥ ë²„íŠ¼
   - íŒŒì¼ ì²¨ë¶€ ê¸°ëŠ¥

3. **ê¸°ëŠ¥ ë²„íŠ¼**
   - í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„
   - ì‹œì¥ ë™í–¥ ì¡°íšŒ
   - íˆ¬ì ì¶”ì²œ ìš”ì²­

### ë°˜ì‘í˜• ë””ìì¸
```css
/* web/static/css/chatbot.css */
.chatbot-container {
    display: flex;
    flex-direction: column;
    height: 100vh;
    max-width: 800px;
    margin: 0 auto;
    background: #f8f9fa;
}

.chat-messages {
    flex: 1;
    overflow-y: auto;
    padding: 20px;
    display: flex;
    flex-direction: column;
    gap: 15px;
}

.message {
    display: flex;
    align-items: flex-start;
    gap: 10px;
    animation: fadeIn 0.3s ease-in;
}

.message.user {
    flex-direction: row-reverse;
}

.message-content {
    max-width: 70%;
    padding: 12px 16px;
    border-radius: 18px;
    word-wrap: break-word;
}

.message.user .message-content {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-bottom-right-radius: 4px;
}

.message.ai .message-content {
    background: white;
    color: #333;
    border: 1px solid #e9ecef;
    border-bottom-left-radius: 4px;
}

.chat-input {
    padding: 20px;
    background: white;
    border-top: 1px solid #e9ecef;
    display: flex;
    gap: 10px;
    align-items: center;
}

.input-field {
    flex: 1;
    padding: 12px 16px;
    border: 2px solid #e9ecef;
    border-radius: 25px;
    outline: none;
    transition: border-color 0.3s ease;
}

.input-field:focus {
    border-color: #667eea;
}

.send-button {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border: none;
    padding: 12px 20px;
    border-radius: 25px;
    cursor: pointer;
    transition: transform 0.2s ease;
}

.send-button:hover {
    transform: translateY(-2px);
}

/* íƒ€ì´í•‘ ì• ë‹ˆë©”ì´ì…˜ */
.typing-indicator {
    display: flex;
    gap: 4px;
    padding: 12px 16px;
    background: white;
    border-radius: 18px;
    border-bottom-left-radius: 4px;
    max-width: 60px;
}

.typing-dot {
    width: 8px;
    height: 8px;
    background: #667eea;
    border-radius: 50%;
    animation: typing 1.4s infinite ease-in-out;
}

.typing-dot:nth-child(1) { animation-delay: -0.32s; }
.typing-dot:nth-child(2) { animation-delay: -0.16s; }

@keyframes typing {
    0%, 80%, 100% { transform: scale(0); }
    40% { transform: scale(1); }
}

@keyframes fadeIn {
    from { opacity: 0; transform: translateY(10px); }
    to { opacity: 1; transform: translateY(0); }
}
```

## ğŸ”§ í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„

### 1. ë‹¤ì¤‘ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
```python
# web/services/ai_chat_service.py
class AIChatService:
    def __init__(self):
        self.openai_client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))
        self.conversation_memory = {}
        self.user_profiles = {}
    
    def process_chat_message(self, user_id: str, message: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¤ì¤‘ AI ì—ì´ì „íŠ¸ë¥¼ í†µí•œ ë©”ì‹œì§€ ì²˜ë¦¬"""
        try:
            # 1ë‹¨ê³„: AI-A ì´ˆê¸° ë¶„ì„
            ai_a_response = self.generate_ai_a_response(message, context)
            
            # 2ë‹¨ê³„: AI-A2 ì§ˆë¬¸ ì •ì œ
            ai_a2_response = self.generate_ai_a2_response(message, ai_a_response, context)
            
            # 3ë‹¨ê³„: AI-B ë°ì´í„° ë¶„ì„
            ai_b_response = self.generate_ai_b_response(ai_a2_response, context)
            
            # 4ë‹¨ê³„: ìµœì¢… ì‘ë‹µ ìƒì„±
            final_response = self.generate_final_response(
                original_message=message,
                ai_a_response=ai_a_response,
                ai_a2_response=ai_a2_response,
                ai_b_response=ai_b_response,
                context=context
            )
            
            # ëŒ€í™” ê¸°ë¡ ì €ì¥
            self.save_conversation(user_id, message, final_response)
            
            return {
                'response': final_response,
                'confidence': self.calculate_confidence(final_response),
                'suggestions': self.generate_suggestions(context),
                'analysis': {
                    'ai_a': ai_a_response,
                    'ai_a2': ai_a2_response,
                    'ai_b': ai_b_response
                }
            }
            
        except Exception as e:
            logger.error(f"AI ì±—ë´‡ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'response': "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                'error': True
            }
    
    def generate_ai_a_response(self, message: str, context: Dict[str, Any]) -> str:
        """AI-A: ì´ˆê¸° ì‚¬ìš©ì ì˜ë„ ë¶„ì„"""
        prompt = f"""
        ì‚¬ìš©ìì˜ íˆ¬ì ê´€ë ¨ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì´ˆê¸° ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.
        
        ì‚¬ìš©ì ë©”ì‹œì§€: {message}
        ì‚¬ìš©ì í”„ë¡œí•„: {context.get('user_profile', {})}
        ëŒ€í™” ì»¨í…ìŠ¤íŠ¸: {context.get('conversation_history', [])}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
        1. ì§ˆë¬¸ ì˜ë„ ë¶„ì„
        2. í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        3. ì´ˆê¸° ì‘ë‹µ ìƒì„±
        """
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=500,
            temperature=0.7
        )
        
        return response.choices[0].message.content
    
    def generate_ai_a2_response(self, message: str, ai_a_response: str, context: Dict[str, Any]) -> str:
        """AI-A2: ì§ˆë¬¸ ì •ì œ ë° ìƒì„¸ ë¶„ì„"""
        prompt = f"""
        AI-Aì˜ ì´ˆê¸° ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì •ì œí•˜ê³  ìƒì„¸ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.
        
        ì›ë³¸ ë©”ì‹œì§€: {message}
        AI-A ë¶„ì„: {ai_a_response}
        ì‚¬ìš©ì í”„ë¡œí•„: {context.get('user_profile', {})}
        
        ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:
        1. ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ íŒŒì•…
        2. í•„ìš”í•œ ì¶”ê°€ ì •ë³´ ì‹ë³„
        3. êµ¬ì²´ì ì¸ ë¶„ì„ ë°©í–¥ ì„¤ì •
        """
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=400,
            temperature=0.6
        )
        
        return response.choices[0].message.content
    
    def generate_ai_b_response(self, ai_a2_response: str, context: Dict[str, Any]) -> str:
        """AI-B: ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ë° ì¶”ì²œ"""
        prompt = f"""
        AI-A2ì˜ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ íˆ¬ì ë°ì´í„°ë¥¼ í™œìš©í•œ êµ¬ì²´ì ì¸ ë¶„ì„ê³¼ ì¶”ì²œì„ ì œê³µí•˜ì„¸ìš”.
        
        AI-A2 ë¶„ì„: {ai_a2_response}
        ì‹œì¥ ë°ì´í„°: {context.get('market_data', {})}
        ì‚¬ìš©ì í¬íŠ¸í´ë¦¬ì˜¤: {context.get('user_portfolio', {})}
        
        ë‹¤ìŒì„ í¬í•¨í•˜ì—¬ ì‘ë‹µí•˜ì„¸ìš”:
        1. ê´€ë ¨ ì¢…ëª© ë¶„ì„
        2. ì‹œì¥ ë™í–¥ ë¶„ì„
        3. êµ¬ì²´ì ì¸ íˆ¬ì ì¶”ì²œ
        4. ìœ„í—˜ ìš”ì†Œ ê³ ë ¤ì‚¬í•­
        """
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=600,
            temperature=0.5
        )
        
        return response.choices[0].message.content
    
    def generate_final_response(self, original_message: str, ai_a_response: str, 
                              ai_a2_response: str, ai_b_response: str, context: Dict[str, Any]) -> str:
        """ìµœì¢… ì‘ë‹µ ìƒì„±"""
        prompt = f"""
        ëª¨ë“  AI ì—ì´ì „íŠ¸ì˜ ë¶„ì„ì„ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ìµœì í™”ëœ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.
        
        ì›ë³¸ ì§ˆë¬¸: {original_message}
        AI-A ë¶„ì„: {ai_a_response}
        AI-A2 ì •ì œ: {ai_a2_response}
        AI-B ë¶„ì„: {ai_b_response}
        ì‚¬ìš©ì í”„ë¡œí•„: {context.get('user_profile', {})}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
        1. ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í†¤
        2. êµ¬ì²´ì ì¸ ë°ì´í„°ì™€ ì˜ˆì‹œ í¬í•¨
        3. ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ
        4. ì¶”ê°€ ì§ˆë¬¸ ìœ ë„
        """
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=800,
            temperature=0.7
        )
        
        return response.choices[0].message.content
```

### 2. ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬
```python
# web/services/memory_service.py
class MemoryService:
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
    
    def save_conversation(self, user_id: str, message: str, response: str):
        """ëŒ€í™” ê¸°ë¡ ì €ì¥"""
        try:
            conversation_key = f"conversation:{user_id}"
            
            # ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
            existing_conversation = self.redis_client.get(conversation_key)
            conversation = json.loads(existing_conversation) if existing_conversation else []
            
            # ìƒˆë¡œìš´ ëŒ€í™” ì¶”ê°€
            conversation.append({
                'timestamp': datetime.now().isoformat(),
                'user_message': message,
                'ai_response': response,
                'message_id': str(uuid.uuid4())
            })
            
            # ìµœê·¼ 50ê°œ ëŒ€í™”ë§Œ ìœ ì§€
            if len(conversation) > 50:
                conversation = conversation[-50:]
            
            # Redisì— ì €ì¥ (24ì‹œê°„ ë§Œë£Œ)
            self.redis_client.setex(conversation_key, 86400, json.dumps(conversation))
            
        except Exception as e:
            logger.error(f"ëŒ€í™” ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_conversation_history(self, user_id: str, limit: int = 10) -> List[Dict[str, Any]]:
        """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
        try:
            conversation_key = f"conversation:{user_id}"
            conversation_data = self.redis_client.get(conversation_key)
            
            if conversation_data:
                conversation = json.loads(conversation_data)
                return conversation[-limit:] if limit else conversation
            
            return []
            
        except Exception as e:
            logger.error(f"ëŒ€í™” ê¸°ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_user_context(self, user_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ"""
        try:
            # ìµœê·¼ ëŒ€í™” ê¸°ë¡
            recent_conversations = self.get_conversation_history(user_id, 5)
            
            # ì‚¬ìš©ì í”„ë¡œí•„
            user_profile = self.get_user_profile(user_id)
            
            # ì‹œì¥ ë°ì´í„°
            market_data = self.get_current_market_data()
            
            return {
                'conversation_history': recent_conversations,
                'user_profile': user_profile,
                'market_data': market_data,
                'session_info': {
                    'user_id': user_id,
                    'session_start': datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
```

### 3. ì‹¤ì‹œê°„ ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤
```javascript
// web/static/js/chatbot.js
class ChatbotManager {
    constructor() {
        this.messages = [];
        this.isTyping = false;
        this.userId = this.getUserId();
        this.init();
    }
    
    init() {
        this.setupEventListeners();
        this.loadChatHistory();
        this.showWelcomeMessage();
    }
    
    setupEventListeners() {
        const inputField = document.getElementById('chat-input');
        const sendButton = document.getElementById('send-button');
        
        inputField.addEventListener('keypress', (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                this.sendMessage();
            }
        });
        
        sendButton.addEventListener('click', () => {
            this.sendMessage();
        });
        
        // ìŒì„± ì…ë ¥ ë²„íŠ¼
        const voiceButton = document.getElementById('voice-button');
        if (voiceButton) {
            voiceButton.addEventListener('click', () => {
                this.startVoiceInput();
            });
        }
    }
    
    async sendMessage() {
        const inputField = document.getElementById('chat-input');
        const message = inputField.value.trim();
        
        if (!message || this.isTyping) return;
        
        // ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        this.addMessage(message, 'user');
        inputField.value = '';
        
        // íƒ€ì´í•‘ í‘œì‹œ
        this.showTypingIndicator();
        
        try {
            // AI ì‘ë‹µ ìš”ì²­
            const response = await fetch('/api/chat/send', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    message: message,
                    user_id: this.userId
                })
            });
            
            const data = await response.json();
            
            // íƒ€ì´í•‘ í‘œì‹œ ì œê±°
            this.hideTypingIndicator();
            
            if (data.success) {
                // AI ì‘ë‹µ í‘œì‹œ
                this.addMessage(data.response, 'ai');
                
                // ì œì•ˆì‚¬í•­ í‘œì‹œ
                if (data.suggestions && data.suggestions.length > 0) {
                    this.showSuggestions(data.suggestions);
                }
            } else {
                this.addMessage("ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", 'ai');
            }
            
        } catch (error) {
            console.error('ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨:', error);
            this.hideTypingIndicator();
            this.addMessage("ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", 'ai');
        }
    }
    
    addMessage(content, sender) {
        const messagesContainer = document.getElementById('chat-messages');
        const messageDiv = document.createElement('div');
        messageDiv.className = `message ${sender}`;
        
        const avatar = document.createElement('div');
        avatar.className = 'message-avatar';
        avatar.innerHTML = sender === 'user' ? 'ğŸ‘¤' : 'ğŸ¤–';
        
        const messageContent = document.createElement('div');
        messageContent.className = 'message-content';
        messageContent.innerHTML = this.formatMessage(content);
        
        messageDiv.appendChild(avatar);
        messageDiv.appendChild(messageContent);
        
        messagesContainer.appendChild(messageDiv);
        messagesContainer.scrollTop = messagesContainer.scrollHeight;
        
        // ë©”ì‹œì§€ ì €ì¥
        this.messages.push({
            sender: sender,
            content: content,
            timestamp: new Date().toISOString()
        });
    }
    
    formatMessage(content) {
        // ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì§€ì›
        return marked.parse(content);
    }
    
    showTypingIndicator() {
        this.isTyping = true;
        const messagesContainer = document.getElementById('chat-messages');
        const typingDiv = document.createElement('div');
        typingDiv.className = 'message ai typing-indicator-container';
        typingDiv.id = 'typing-indicator';
        
        typingDiv.innerHTML = `
            <div class="message-avatar">ğŸ¤–</div>
            <div class="typing-indicator">
                <div class="typing-dot"></div>
                <div class="typing-dot"></div>
                <div class="typing-dot"></div>
            </div>
        `;
        
        messagesContainer.appendChild(typingDiv);
        messagesContainer.scrollTop = messagesContainer.scrollHeight;
    }
    
    hideTypingIndicator() {
        this.isTyping = false;
        const typingIndicator = document.getElementById('typing-indicator');
        if (typingIndicator) {
            typingIndicator.remove();
        }
    }
    
    showSuggestions(suggestions) {
        const suggestionsContainer = document.createElement('div');
        suggestionsContainer.className = 'suggestions-container';
        
        suggestions.forEach(suggestion => {
            const button = document.createElement('button');
            button.className = 'suggestion-button';
            button.textContent = suggestion;
            button.addEventListener('click', () => {
                document.getElementById('chat-input').value = suggestion;
                this.sendMessage();
            });
            suggestionsContainer.appendChild(button);
        });
        
        const messagesContainer = document.getElementById('chat-messages');
        messagesContainer.appendChild(suggestionsContainer);
        messagesContainer.scrollTop = messagesContainer.scrollHeight;
    }
    
    async loadChatHistory() {
        try {
            const response = await fetch(`/api/chat/history?user_id=${this.userId}`);
            const history = await response.json();
            
            if (history.success && history.messages) {
                history.messages.forEach(msg => {
                    this.addMessage(msg.content, msg.sender);
                });
            }
        } catch (error) {
            console.error('ì±„íŒ… ê¸°ë¡ ë¡œë“œ ì‹¤íŒ¨:', error);
        }
    }
    
    showWelcomeMessage() {
        const welcomeMessage = `
ì•ˆë…•í•˜ì„¸ìš”! Pixie AI íˆ¬ì ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ğŸ‘‹

ì €ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

ğŸ“Š **í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„**
- í˜„ì¬ ë³´ìœ  ì¢…ëª© ë¶„ì„
- íˆ¬ì ì„±ê³¼ í‰ê°€
- ë¦¬ë°¸ëŸ°ì‹± ì¶”ì²œ

ğŸ“ˆ **ì‹œì¥ ë™í–¥ ë¶„ì„**
- ì‹¤ì‹œê°„ ì‹œì¥ ì •ë³´
- ì„¹í„°ë³„ ë™í–¥ ë¶„ì„
- íˆ¬ì ê¸°íšŒ íƒìƒ‰

ğŸ’¡ **íˆ¬ì ìƒë‹´**
- ê°œì¸í™”ëœ íˆ¬ì ì „ëµ
- ìœ„í—˜ ê´€ë¦¬ ì¡°ì–¸
- íˆ¬ì êµìœ¡ ìë£Œ

ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?
        `;
        
        this.addMessage(welcomeMessage, 'ai');
    }
}
```

## ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°

### ì±—ë´‡ ê´€ë ¨ í…Œì´ë¸”
```sql
CREATE TABLE chat_conversations (
    id SERIAL PRIMARY KEY,
    user_id VARCHAR(50) NOT NULL,
    session_id VARCHAR(100) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE chat_messages (
    id SERIAL PRIMARY KEY,
    conversation_id INTEGER REFERENCES chat_conversations(id),
    sender VARCHAR(10) NOT NULL, -- 'user' or 'ai'
    content TEXT NOT NULL,
    message_type VARCHAR(20) DEFAULT 'text', -- 'text', 'image', 'file'
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE ai_analysis_logs (
    id SERIAL PRIMARY KEY,
    user_id VARCHAR(50) NOT NULL,
    original_message TEXT NOT NULL,
    ai_a_response TEXT,
    ai_a2_response TEXT,
    ai_b_response TEXT,
    final_response TEXT NOT NULL,
    processing_time DECIMAL(10,3),
    confidence_score DECIMAL(5,2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE user_chat_preferences (
    id SERIAL PRIMARY KEY,
    user_id VARCHAR(50) UNIQUE NOT NULL,
    preferred_language VARCHAR(10) DEFAULT 'ko',
    response_style VARCHAR(20) DEFAULT 'friendly',
    detail_level VARCHAR(20) DEFAULT 'moderate',
    notification_enabled BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## ğŸ”„ ì‹¤ì‹œê°„ í†µì‹ 

### WebSocket ì—°ê²°
```python
# web/services/websocket_service.py
from flask_socketio import SocketIO, emit, join_room, leave_room

class WebSocketService:
    def __init__(self, socketio):
        self.socketio = socketio
        self.setup_handlers()
    
    def setup_handlers(self):
        @self.socketio.on('connect')
        def handle_connect():
            print('Client connected')
            emit('connected', {'data': 'Connected'})
        
        @self.socketio.on('join')
        def handle_join(data):
            room = data['room']
            join_room(room)
            emit('status', {'msg': f'Joined room: {room}'}, room=room)
        
        @self.socketio.on('chat_message')
        def handle_chat_message(data):
            user_id = data['user_id']
            message = data['message']
            
            # AI ì²˜ë¦¬
            ai_service = AIChatService()
            context = self.get_user_context(user_id)
            response = ai_service.process_chat_message(user_id, message, context)
            
            # ì‹¤ì‹œê°„ ì‘ë‹µ ì „ì†¡
            emit('ai_response', {
                'response': response['response'],
                'suggestions': response.get('suggestions', []),
                'timestamp': datetime.now().isoformat()
            }, room=user_id)
```

## ğŸ” ë³´ì•ˆ ë° ê°œì¸ì •ë³´ ë³´í˜¸

### ëŒ€í™” ë°ì´í„° ì•”í˜¸í™”
```python
# web/services/chat_security_service.py
class ChatSecurityService:
    def __init__(self):
        self.encryption_key = os.environ.get('CHAT_ENCRYPTION_KEY')
    
    def encrypt_message(self, message: str) -> str:
        """ë©”ì‹œì§€ ì•”í˜¸í™”"""
        from cryptography.fernet import Fernet
        f = Fernet(self.encryption_key)
        return f.encrypt(message.encode()).decode()
    
    def decrypt_message(self, encrypted_message: str) -> str:
        """ë©”ì‹œì§€ ë³µí˜¸í™”"""
        from cryptography.fernet import Fernet
        f = Fernet(self.encryption_key)
        return f.decrypt(encrypted_message.encode()).decode()
    
    def sanitize_user_input(self, message: str) -> str:
        """ì‚¬ìš©ì ì…ë ¥ ì •ì œ"""
        import html
        # HTML íƒœê·¸ ì œê±°
        message = html.escape(message)
        # ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸ ì œê±°
        message = message.replace('<script>', '').replace('</script>', '')
        return message.strip()
    
    def validate_message_length(self, message: str) -> bool:
        """ë©”ì‹œì§€ ê¸¸ì´ ê²€ì¦"""
        return len(message) <= 1000  # ìµœëŒ€ 1000ì
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ì‘ë‹µ ìºì‹±
```python
# web/services/chat_cache_service.py
class ChatCacheService:
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
    
    def cache_ai_response(self, message_hash: str, response: Dict[str, Any]):
        """AI ì‘ë‹µ ìºì‹±"""
        cache_key = f"ai_response:{message_hash}"
        self.redis_client.setex(cache_key, 3600, json.dumps(response))  # 1ì‹œê°„
    
    def get_cached_response(self, message_hash: str) -> Optional[Dict[str, Any]]:
        """ìºì‹œëœ ì‘ë‹µ ì¡°íšŒ"""
        cache_key = f"ai_response:{message_hash}"
        cached_data = self.redis_client.get(cache_key)
        return json.loads(cached_data) if cached_data else None
    
    def generate_message_hash(self, message: str, user_context: Dict[str, Any]) -> str:
        """ë©”ì‹œì§€ í•´ì‹œ ìƒì„±"""
        import hashlib
        context_str = json.dumps(user_context, sort_keys=True)
        return hashlib.md5(f"{message}{context_str}".encode()).hexdigest()
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ëµ

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# tests/test_ai_chat_service.py
import pytest
from web.services.ai_chat_service import AIChatService

class TestAIChatService:
    def test_process_chat_message(self):
        """ì±—ë´‡ ë©”ì‹œì§€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        service = AIChatService()
        user_id = "test_user_123"
        message = "ì‚¼ì„±ì „ì ì£¼ì‹ì— íˆ¬ìí•˜ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ ìƒê°í•˜ì„¸ìš”?"
        context = {
            'user_profile': {'risk_tolerance': 70},
            'market_data': {'samsung': {'price': 70000}}
        }
        
        result = service.process_chat_message(user_id, message, context)
        
        assert 'response' in result
        assert 'confidence' in result
        assert isinstance(result['response'], str)
        assert len(result['response']) > 0
    
    def test_ai_agent_chain(self):
        """AI ì—ì´ì „íŠ¸ ì²´ì¸ í…ŒìŠ¤íŠ¸"""
        service = AIChatService()
        message = "íˆ¬ì í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”"
        context = {}
        
        # ê° AI ì—ì´ì „íŠ¸ ì‘ë‹µ í…ŒìŠ¤íŠ¸
        ai_a_response = service.generate_ai_a_response(message, context)
        assert len(ai_a_response) > 0
        
        ai_a2_response = service.generate_ai_a2_response(message, ai_a_response, context)
        assert len(ai_a2_response) > 0
        
        ai_b_response = service.generate_ai_b_response(ai_a2_response, context)
        assert len(ai_b_response) > 0
```

## ğŸš€ ë°°í¬ ë° ìš´ì˜

### í™˜ê²½ ì„¤ì •
```python
# web/config/chatbot_config.py
class ChatbotConfig:
    # AI ëª¨ë¸ ì„¤ì •
    OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')
    OPENAI_MODEL = "gpt-4o-mini"
    MAX_TOKENS = 1000
    TEMPERATURE = 0.7
    
    # ëŒ€í™” ì„¤ì •
    MAX_MESSAGE_LENGTH = 1000
    MAX_CONVERSATION_HISTORY = 50
    SESSION_TIMEOUT = 3600  # 1ì‹œê°„
    
    # ìºì‹œ ì„¤ì •
    RESPONSE_CACHE_TTL = 3600  # 1ì‹œê°„
    CONVERSATION_CACHE_TTL = 86400  # 24ì‹œê°„
    
    # ë³´ì•ˆ ì„¤ì •
    CHAT_ENCRYPTION_KEY = os.environ.get('CHAT_ENCRYPTION_KEY')
    RATE_LIMIT_PER_MINUTE = 30
```

## ğŸ“Š ë¶„ì„ ë° ê°œì„ 

### ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë¶„ì„
```python
# web/services/chat_analytics_service.py
class ChatAnalyticsService:
    def analyze_chat_interactions(self) -> Dict[str, Any]:
        """ì±—ë´‡ ìƒí˜¸ì‘ìš© ë¶„ì„"""
        return {
            'daily_active_users': self.get_daily_active_users(),
            'average_conversation_length': self.get_avg_conversation_length(),
            'popular_topics': self.get_popular_topics(),
            'user_satisfaction': self.calculate_satisfaction_score(),
            'response_time_analysis': self.analyze_response_times()
        }
    
    def get_popular_topics(self) -> List[Dict[str, Any]]:
        """ì¸ê¸° ì£¼ì œ ë¶„ì„"""
        # ìµœê·¼ 7ì¼ê°„ì˜ ëŒ€í™” ë°ì´í„° ë¶„ì„
        recent_conversations = self.query_recent_conversations(days=7)
        
        topic_counts = {}
        for conv in recent_conversations:
            topics = self.extract_topics(conv['content'])
            for topic in topics:
                topic_counts[topic] = topic_counts.get(topic, 0) + 1
        
        return sorted(topic_counts.items(), key=lambda x: x[1], reverse=True)[:10]
```

## ğŸ”„ í–¥í›„ ê°œì„  ê³„íš

### ë‹¨ê¸° ê°œì„ ì‚¬í•­ (1-2ê°œì›”)
1. **ìŒì„± ì¸ì‹** ê¸°ëŠ¥ ì¶”ê°€
2. **ì´ë¯¸ì§€ ë¶„ì„** ê¸°ëŠ¥
3. **ë‹¤êµ­ì–´ ì§€ì›** í™•ëŒ€
4. **ì‹¤ì‹œê°„ ë²ˆì—­** ê¸°ëŠ¥

### ì¤‘ê¸° ê°œì„ ì‚¬í•­ (3-6ê°œì›”)
1. **ê°ì • ë¶„ì„** í†µí•©
2. **ê°œì¸í™”ëœ AI ëª¨ë¸** í›ˆë ¨
3. **ë©€í‹°ëª¨ë‹¬** ëŒ€í™” ì§€ì›
4. **ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„°** ì—°ë™

### ì¥ê¸° ê°œì„ ì‚¬í•­ (6ê°œì›” ì´ìƒ)
1. **AR/VR ì±—ë´‡** ì¸í„°í˜ì´ìŠ¤
2. **ë¸”ë¡ì²´ì¸ ê¸°ë°˜** íˆ¬ì ê¸°ë¡
3. **AI íŠœí„°** ì‹œìŠ¤í…œ
4. **ê¸€ë¡œë²Œ íˆ¬ì** ìƒë‹´

## ğŸ“š ì°¸ê³  ìë£Œ

### ê¸°ìˆ  ìŠ¤íƒ
- **í”„ë¡ íŠ¸ì—”ë“œ**: HTML5, CSS3, JavaScript (ES6+)
- **ë°±ì—”ë“œ**: Python Flask
- **AI/ML**: OpenAI GPT-4, TensorFlow
- **ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL, Redis
- **ì‹¤ì‹œê°„ í†µì‹ **: WebSocket, Socket.IO

### ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë„êµ¬
- **UI í”„ë ˆì„ì›Œí¬**: Bootstrap 5
- **ë§ˆí¬ë‹¤ìš´**: Marked.js
- **ìŒì„± ì¸ì‹**: Web Speech API
- **í…ŒìŠ¤íŠ¸**: pytest, Selenium
- **ëª¨ë‹ˆí„°ë§**: Prometheus, Grafana

ì´ ë¬¸ì„œëŠ” Pixie íˆ¬ìì±—ë´‡ì˜ AI ì±—ë´‡ ì‹œìŠ¤í…œ ê°œë°œ ê³¼ì •ê³¼ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ì„ ìƒì„¸íˆ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ì§€ì†ì ì¸ AI ëª¨ë¸ ê°œì„ ê³¼ ì‚¬ìš©ì ê²½í—˜ í–¥ìƒì„ í†µí•´ ë”ìš± ì •í™•í•˜ê³  ìœ ìš©í•œ íˆ¬ì ìƒë‹´ì„ ì œê³µí•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. 